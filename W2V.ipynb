{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def word_embedding(\n",
    "        df: pd.DataFrame, \n",
    "        vector_size=1000, \n",
    "        w2v_epochs = 30,\n",
    "        aggregate = \"mean\",\n",
    "        colname = \"text\"\n",
    "    ):\n",
    "    word_vector = []\n",
    "    text_col = df[colname]\n",
    "    tokenized_text = [simple_preprocess(line, deacc=True) for line in text_col]\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [[porter_stemmer.stem(word) for word in tokens] for tokens in tokenized_text]\n",
    "    \n",
    "    w2v_model = Word2Vec(sentences=stemmed_tokens, vector_size=vector_size, window=5, min_count=1, workers=4, sg=1)\n",
    "    # below is added to Mike's version\n",
    "\n",
    "    w2v_model.build_vocab(stemmed_tokens)\n",
    "    w2v_model.train(\n",
    "        stemmed_tokens, \n",
    "        total_examples=len(stemmed_tokens), \n",
    "        epochs=w2v_epochs\n",
    "    )\n",
    "\n",
    "    # above is added to Mike's version\n",
    "    \n",
    "    for index, row in enumerate(stemmed_tokens):\n",
    "        model_vector = np.zeros((vector_size, len(row)))\n",
    "        for tok_id, token in enumerate(row):\n",
    "            if token in w2v_model.wv:\n",
    "                model_vector[:, tok_id] = w2v_model.wv[token]\n",
    "        \n",
    "        if len(stemmed_tokens[index]) == 0:\n",
    "            word_vector.append([0]*vector_size)\n",
    "        else:\n",
    "            mu = np.mean(model_vector, axis = 1)\n",
    "            M = np.max(model_vector, axis = 1)\n",
    "            if aggregate == \"mean\":\n",
    "                word_vector.append(mu)\n",
    "            elif aggregate == \"max\":\n",
    "                word_vector.append(M)\n",
    "            elif aggregate == \"mean_max\":\n",
    "                word_vector.append(M + mu)\n",
    "    \n",
    "    return pd.DataFrame(word_vector, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linru\\AppData\\Roaming\\Python\\Python39\\site-packages\\dateutil\\parser\\_parser.py:1213: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>weekday_Mon</th>\n",
       "      <th>weekday_Tue</th>\n",
       "      <th>weekday_Wed</th>\n",
       "      <th>weekday_Thu</th>\n",
       "      <th>weekday_Fri</th>\n",
       "      <th>weekday_Sat</th>\n",
       "      <th>weekday_Sun</th>\n",
       "      <th>datetime</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000570</td>\n",
       "      <td>4</td>\n",
       "      <td>1880006855</td>\n",
       "      <td>Thu May 21 23:48:34 PDT 2009</td>\n",
       "      <td>JohnnyEugenio2</td>\n",
       "      <td>Omgosh I put my phone back on the hook so the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-05-21 23:48:34</td>\n",
       "      <td>omgosh i put phone back hook battery die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>991406</td>\n",
       "      <td>4</td>\n",
       "      <td>1835115440</td>\n",
       "      <td>Mon May 18 05:10:48 PDT 2009</td>\n",
       "      <td>BalaSN</td>\n",
       "      <td>leavin ma office</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-05-18 05:10:48</td>\n",
       "      <td>leavin office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1534391</td>\n",
       "      <td>4</td>\n",
       "      <td>2178760886</td>\n",
       "      <td>Mon Jun 15 08:10:05 PDT 2009</td>\n",
       "      <td>eltorgie</td>\n",
       "      <td>thunder!  ... 399/1000 words</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-06-15 08:10:05</td>\n",
       "      <td>thunder word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1426117</td>\n",
       "      <td>4</td>\n",
       "      <td>2059166942</td>\n",
       "      <td>Sat Jun 06 16:22:57 PDT 2009</td>\n",
       "      <td>naughtymeg</td>\n",
       "      <td>@chasesterling guess its just me and you!!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-06-06 16:22:57</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120705</td>\n",
       "      <td>0</td>\n",
       "      <td>1833295442</td>\n",
       "      <td>Sun May 17 22:51:09 PDT 2009</td>\n",
       "      <td>Rachel_Butts</td>\n",
       "      <td>@zeneth7 Keen-o! I'm gonna miss you too  I'm g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009-05-17 22:51:09</td>\n",
       "      <td>keeno i going miss i glad hear got home okay i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  target         ids                          date            user  \\\n",
       "0  1000570       4  1880006855  Thu May 21 23:48:34 PDT 2009  JohnnyEugenio2   \n",
       "1   991406       4  1835115440  Mon May 18 05:10:48 PDT 2009          BalaSN   \n",
       "2  1534391       4  2178760886  Mon Jun 15 08:10:05 PDT 2009        eltorgie   \n",
       "3  1426117       4  2059166942  Sat Jun 06 16:22:57 PDT 2009      naughtymeg   \n",
       "4   120705       0  1833295442  Sun May 17 22:51:09 PDT 2009    Rachel_Butts   \n",
       "\n",
       "                                                text  weekday_Mon  \\\n",
       "0  Omgosh I put my phone back on the hook so the ...          0.0   \n",
       "1                                  leavin ma office           1.0   \n",
       "2                       thunder!  ... 399/1000 words          1.0   \n",
       "3        @chasesterling guess its just me and you!!           0.0   \n",
       "4  @zeneth7 Keen-o! I'm gonna miss you too  I'm g...          0.0   \n",
       "\n",
       "   weekday_Tue  weekday_Wed  weekday_Thu  weekday_Fri  weekday_Sat  \\\n",
       "0          0.0          0.0          1.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          1.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   weekday_Sun             datetime  \\\n",
       "0          0.0  2009-05-21 23:48:34   \n",
       "1          0.0  2009-05-18 05:10:48   \n",
       "2          0.0  2009-06-15 08:10:05   \n",
       "3          0.0  2009-06-06 16:22:57   \n",
       "4          1.0  2009-05-17 22:51:09   \n",
       "\n",
       "                                      processed_text  \n",
       "0           omgosh i put phone back hook battery die  \n",
       "1                                      leavin office  \n",
       "2                                       thunder word  \n",
       "3                                              guess  \n",
       "4  keeno i going miss i glad hear got home okay i...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import my_globals\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from utils import get_sub_featured_datasets, get_sub_dataset, get_entire_dataset\n",
    "from preprocessing import cleaning, preprocess_pipeline\n",
    "\n",
    "data = get_sub_dataset(size = 30000, random_seed=4)\n",
    "# data = get_entire_dataset()\n",
    "data = cleaning(data)\n",
    "data[\"processed_text\"] = data[\"text\"].apply(\n",
    "    lambda s:\n",
    "    preprocess_pipeline(\n",
    "        s,\n",
    "        pipeline = \"w2v\"\n",
    "    )\n",
    ")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226939</td>\n",
       "      <td>-0.077200</td>\n",
       "      <td>0.046836</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>-0.174015</td>\n",
       "      <td>-0.039666</td>\n",
       "      <td>-0.022925</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>-0.063925</td>\n",
       "      <td>-0.015890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031321</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.112615</td>\n",
       "      <td>0.034528</td>\n",
       "      <td>0.100905</td>\n",
       "      <td>0.115833</td>\n",
       "      <td>-0.158789</td>\n",
       "      <td>-0.056987</td>\n",
       "      <td>-0.090856</td>\n",
       "      <td>-0.008623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150168</td>\n",
       "      <td>0.035708</td>\n",
       "      <td>0.033201</td>\n",
       "      <td>0.116680</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>-0.060394</td>\n",
       "      <td>0.130485</td>\n",
       "      <td>-0.045609</td>\n",
       "      <td>0.044399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115715</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>0.126036</td>\n",
       "      <td>-0.031151</td>\n",
       "      <td>0.171666</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>-0.292001</td>\n",
       "      <td>-0.069712</td>\n",
       "      <td>0.036156</td>\n",
       "      <td>-0.168498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.321827</td>\n",
       "      <td>0.137617</td>\n",
       "      <td>0.054271</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>-0.148799</td>\n",
       "      <td>0.123119</td>\n",
       "      <td>-0.022908</td>\n",
       "      <td>-0.106843</td>\n",
       "      <td>-0.114478</td>\n",
       "      <td>0.139248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045055</td>\n",
       "      <td>0.070155</td>\n",
       "      <td>0.196001</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>-0.017394</td>\n",
       "      <td>0.214227</td>\n",
       "      <td>-0.096710</td>\n",
       "      <td>-0.002220</td>\n",
       "      <td>0.189984</td>\n",
       "      <td>-0.122219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198427</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>-0.147880</td>\n",
       "      <td>0.157327</td>\n",
       "      <td>-0.137368</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.334117</td>\n",
       "      <td>0.037157</td>\n",
       "      <td>0.169680</td>\n",
       "      <td>0.279199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223727</td>\n",
       "      <td>-0.025341</td>\n",
       "      <td>0.391438</td>\n",
       "      <td>-0.002685</td>\n",
       "      <td>0.422625</td>\n",
       "      <td>0.203378</td>\n",
       "      <td>-0.300448</td>\n",
       "      <td>-0.249923</td>\n",
       "      <td>0.150071</td>\n",
       "      <td>0.120149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244343</td>\n",
       "      <td>0.148029</td>\n",
       "      <td>0.054895</td>\n",
       "      <td>0.098016</td>\n",
       "      <td>0.034683</td>\n",
       "      <td>0.021334</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.080901</td>\n",
       "      <td>-0.104851</td>\n",
       "      <td>0.115776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111992</td>\n",
       "      <td>0.046862</td>\n",
       "      <td>0.147491</td>\n",
       "      <td>-0.071254</td>\n",
       "      <td>0.135095</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>-0.038765</td>\n",
       "      <td>-0.084445</td>\n",
       "      <td>0.079592</td>\n",
       "      <td>-0.040066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.138388</td>\n",
       "      <td>0.165650</td>\n",
       "      <td>0.018332</td>\n",
       "      <td>-0.017240</td>\n",
       "      <td>-0.037595</td>\n",
       "      <td>-0.093409</td>\n",
       "      <td>-0.026791</td>\n",
       "      <td>0.096395</td>\n",
       "      <td>-0.073940</td>\n",
       "      <td>0.025992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085586</td>\n",
       "      <td>-0.070778</td>\n",
       "      <td>0.156444</td>\n",
       "      <td>-0.049311</td>\n",
       "      <td>0.114706</td>\n",
       "      <td>-0.055475</td>\n",
       "      <td>-0.116208</td>\n",
       "      <td>-0.088952</td>\n",
       "      <td>-0.091209</td>\n",
       "      <td>0.102135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.142648</td>\n",
       "      <td>0.114404</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.223302</td>\n",
       "      <td>-0.078325</td>\n",
       "      <td>0.079454</td>\n",
       "      <td>-0.090101</td>\n",
       "      <td>0.113498</td>\n",
       "      <td>-0.236704</td>\n",
       "      <td>0.137507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027308</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>0.150598</td>\n",
       "      <td>-0.169766</td>\n",
       "      <td>0.058294</td>\n",
       "      <td>-0.060453</td>\n",
       "      <td>-0.122161</td>\n",
       "      <td>0.069476</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>-0.305304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.110325</td>\n",
       "      <td>0.104602</td>\n",
       "      <td>0.068552</td>\n",
       "      <td>0.099350</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.009816</td>\n",
       "      <td>0.210176</td>\n",
       "      <td>0.018738</td>\n",
       "      <td>-0.025489</td>\n",
       "      <td>0.065739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>-0.213453</td>\n",
       "      <td>0.229559</td>\n",
       "      <td>-0.069741</td>\n",
       "      <td>0.148155</td>\n",
       "      <td>0.106943</td>\n",
       "      <td>-0.094603</td>\n",
       "      <td>-0.114717</td>\n",
       "      <td>0.147705</td>\n",
       "      <td>-0.137738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.074069</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.068054</td>\n",
       "      <td>-0.090557</td>\n",
       "      <td>0.033178</td>\n",
       "      <td>-0.020772</td>\n",
       "      <td>-0.149306</td>\n",
       "      <td>0.080679</td>\n",
       "      <td>-0.082706</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061993</td>\n",
       "      <td>-0.174772</td>\n",
       "      <td>0.144231</td>\n",
       "      <td>-0.062404</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>0.081912</td>\n",
       "      <td>-0.094581</td>\n",
       "      <td>-0.036566</td>\n",
       "      <td>0.052642</td>\n",
       "      <td>-0.048333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.324604</td>\n",
       "      <td>0.131639</td>\n",
       "      <td>0.155328</td>\n",
       "      <td>-0.086062</td>\n",
       "      <td>-0.061734</td>\n",
       "      <td>-0.023386</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.092988</td>\n",
       "      <td>-0.119909</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233353</td>\n",
       "      <td>-0.075636</td>\n",
       "      <td>-0.005647</td>\n",
       "      <td>-0.156047</td>\n",
       "      <td>0.037365</td>\n",
       "      <td>0.032011</td>\n",
       "      <td>-0.224256</td>\n",
       "      <td>-0.114105</td>\n",
       "      <td>0.149011</td>\n",
       "      <td>-0.094617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.226939 -0.077200  0.046836  0.027473 -0.174015 -0.039666 -0.022925   \n",
       "1      0.150168  0.035708  0.033201  0.116680  0.019111  0.012736 -0.060394   \n",
       "2      0.321827  0.137617  0.054271 -0.053929 -0.148799  0.123119 -0.022908   \n",
       "3      0.198427  0.075223 -0.147880  0.157327 -0.137368  0.004270  0.334117   \n",
       "4      0.244343  0.148029  0.054895  0.098016  0.034683  0.021334  0.052525   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29995  0.138388  0.165650  0.018332 -0.017240 -0.037595 -0.093409 -0.026791   \n",
       "29996  0.142648  0.114404  0.005378  0.223302 -0.078325  0.079454 -0.090101   \n",
       "29997  0.110325  0.104602  0.068552  0.099350  0.014362  0.009816  0.210176   \n",
       "29998  0.074069  0.008730  0.068054 -0.090557  0.033178 -0.020772 -0.149306   \n",
       "29999  0.324604  0.131639  0.155328 -0.086062 -0.061734 -0.023386  0.125654   \n",
       "\n",
       "            7         8         9    ...       990       991       992  \\\n",
       "0     -0.000811 -0.063925 -0.015890  ... -0.031321  0.003946  0.112615   \n",
       "1      0.130485 -0.045609  0.044399  ...  0.115715  0.030940  0.126036   \n",
       "2     -0.106843 -0.114478  0.139248  ...  0.045055  0.070155  0.196001   \n",
       "3      0.037157  0.169680  0.279199  ...  0.223727 -0.025341  0.391438   \n",
       "4      0.080901 -0.104851  0.115776  ... -0.111992  0.046862  0.147491   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "29995  0.096395 -0.073940  0.025992  ... -0.085586 -0.070778  0.156444   \n",
       "29996  0.113498 -0.236704  0.137507  ... -0.027308  0.024873  0.150598   \n",
       "29997  0.018738 -0.025489  0.065739  ...  0.001471 -0.213453  0.229559   \n",
       "29998  0.080679 -0.082706  0.002611  ... -0.061993 -0.174772  0.144231   \n",
       "29999  0.092988 -0.119909  0.012046  ...  0.233353 -0.075636 -0.005647   \n",
       "\n",
       "            993       994       995       996       997       998       999  \n",
       "0      0.034528  0.100905  0.115833 -0.158789 -0.056987 -0.090856 -0.008623  \n",
       "1     -0.031151  0.171666  0.156100 -0.292001 -0.069712  0.036156 -0.168498  \n",
       "2      0.019915 -0.017394  0.214227 -0.096710 -0.002220  0.189984 -0.122219  \n",
       "3     -0.002685  0.422625  0.203378 -0.300448 -0.249923  0.150071  0.120149  \n",
       "4     -0.071254  0.135095  0.007895 -0.038765 -0.084445  0.079592 -0.040066  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "29995 -0.049311  0.114706 -0.055475 -0.116208 -0.088952 -0.091209  0.102135  \n",
       "29996 -0.169766  0.058294 -0.060453 -0.122161  0.069476  0.011877 -0.305304  \n",
       "29997 -0.069741  0.148155  0.106943 -0.094603 -0.114717  0.147705 -0.137738  \n",
       "29998 -0.062404  0.017939  0.081912 -0.094581 -0.036566  0.052642 -0.048333  \n",
       "29999 -0.156047  0.037365  0.032011 -0.224256 -0.114105  0.149011 -0.094617  \n",
       "\n",
       "[30000 rows x 1000 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = word_embedding(data, vector_size=1000, w2v_epochs = 30, aggregate=\"mean\", colname = \"processed_text\")\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing whether W2V can be used with classical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_engineering as fe\n",
    "\n",
    "w2v_df[\"exclaim_freq\"] = data[\"text\"].apply(fe.exclaim_freq)\n",
    "w2v_df[\"mention_count\"] = data[\"text\"].apply(fe.mention_count)\n",
    "w2v_df[\"cap_freq\"] = data[\"text\"].apply(fe.cap_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = w2v_df\n",
    "yy = data[[\"target\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linru\\Anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\linru\\Anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[2142  796]\n",
      " [1022 2040]]\n",
      "\n",
      "accuracy_score:\n",
      "0.697\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70      2938\n",
      "           4       0.72      0.67      0.69      3062\n",
      "\n",
      "    accuracy                           0.70      6000\n",
      "   macro avg       0.70      0.70      0.70      6000\n",
      "weighted avg       0.70      0.70      0.70      6000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linru\\Anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "X_input = X_train\n",
    "bnb.fit(X_input, y_train)\n",
    "y_pred = bnb.predict(\n",
    "    X_test\n",
    ")\n",
    "\n",
    "def assess(y_true, y_pred):\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"accuracy_score:\")\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print()\n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    print()\n",
    "\n",
    "assess(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
